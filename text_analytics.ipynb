{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6bd992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc33d6",
   "metadata": {},
   "source": [
    "# 1 TOKENIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7e94f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\ATHARVA\n",
      "[nltk_data]     MOHITE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " 'used',\n",
       " 'to',\n",
       " 'demonstrate',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'and',\n",
       " 'finding',\n",
       " 'solutions']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "text_data=\"this is sample sentence used to demonstrate tokenization,and finding solutions\"\n",
    "word_tokens=word_tokenize(text_data)\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff667611",
   "metadata": {},
   "source": [
    "# 2 stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60230538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ATHARVA\n",
      "[nltk_data]     MOHITE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sample',\n",
       " 'sentence',\n",
       " 'used',\n",
       " 'demonstrate',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'finding',\n",
       " 'solutions']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "wordsList = [w for w in word_tokens if not w in stop_words]\n",
    " \n",
    "wordsList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397a5c5",
   "metadata": {},
   "source": [
    "# 3 POS TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acf80ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sample', 'JJ'), ('sentence', 'NN'), ('used', 'VBN'), ('demonstrate', 'NN'), ('tokenization', 'NN'), (',', ','), ('finding', 'VBG'), ('solutions', 'NNS')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ATHARVA MOHITE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "tagged = nltk.pos_tag(wordsList)\n",
    "\n",
    "print(tagged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53645b8c",
   "metadata": {},
   "source": [
    "# 4 stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06bf3c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample  :  sampl\n",
      "sentence  :  sentenc\n",
      "used  :  use\n",
      "demonstrate  :  demonstr\n",
      "tokenization  :  token\n",
      ",  :  ,\n",
      "finding  :  find\n",
      "solutions  :  solut\n"
     ]
    }
   ],
   "source": [
    "# import these modules\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "for w in wordsList:\n",
    "\tprint(w, \" : \", ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09570ba",
   "metadata": {},
   "source": [
    "\n",
    "# 5 lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b254538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample  => sample\n",
      "sentence  => sentence\n",
      "used  => used\n",
      "demonstrate  => demonstrate\n",
      "tokenization  => tokenization\n",
      ",  => ,\n",
      "finding  => finding\n",
      "solutions  => solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\ATHARVA\n",
      "[nltk_data]     MOHITE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\ATHARVA\n",
      "[nltk_data]     MOHITE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for w in wordsList:\n",
    "    print( w,\" =>\",lemmatizer.lemmatize(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9610a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['this is apple','ram is boy','she is dancing','ram is looking at apple','ram is not dancing'\n",
    "       ]\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cee68f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   apple  at  boy  dancing  is  looking  not  ram  she  this\n",
      "0      1   0    0        0   1        0    0    0    0     1\n",
      "1      0   0    1        0   1        0    0    1    0     0\n",
      "2      0   0    0        1   1        0    0    0    1     0\n",
      "3      1   1    0        0   1        1    0    1    0     0\n",
      "4      0   0    0        1   1        0    1    1    0     0\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(docs)\n",
    "tf = pd.DataFrame(word_count_vector.toarray(), columns=cv.get_feature_names())\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c13bacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apple</th>\n",
       "      <th>at</th>\n",
       "      <th>boy</th>\n",
       "      <th>dancing</th>\n",
       "      <th>is</th>\n",
       "      <th>looking</th>\n",
       "      <th>not</th>\n",
       "      <th>ram</th>\n",
       "      <th>she</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588732</td>\n",
       "      <td>0.347715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729718</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.442354</td>\n",
       "      <td>0.548286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>0.548286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528947</td>\n",
       "      <td>0.312405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655616</td>\n",
       "      <td>0.439074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      apple        at       boy   dancing        is   looking       not  \\\n",
       "0  0.588732  0.000000  0.000000  0.000000  0.347715  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.772536  0.000000  0.368117  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.588732  0.347715  0.000000  0.000000   \n",
       "3  0.442354  0.548286  0.000000  0.000000  0.261261  0.548286  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.528947  0.312405  0.000000  0.655616   \n",
       "\n",
       "        ram       she      this  \n",
       "0  0.000000  0.000000  0.729718  \n",
       "1  0.517376  0.000000  0.000000  \n",
       "2  0.000000  0.729718  0.000000  \n",
       "3  0.367193  0.000000  0.000000  \n",
       "4  0.439074  0.000000  0.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X = tfidf_vect.fit_transform(docs)\n",
    "X=X.todense()\n",
    "\n",
    "ans= pd.DataFrame(X, columns=tfidf_vect.get_feature_names())\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256703ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381835e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
